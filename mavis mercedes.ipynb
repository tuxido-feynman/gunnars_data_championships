{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAANeCAYAAAB08kU4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV0scpBwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10be0b780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4209 entries, 0 to 4208\n",
      "Columns: 357 entries, ID to X191\n",
      "dtypes: int64(156), uint8(201)\n",
      "memory usage: 5.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4208 entries, 0 to 4207\n",
      "Columns: 352 entries, ID to X191\n",
      "dtypes: float64(1), int64(156), uint8(195)\n",
      "memory usage: 5.9 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from subprocess import check_output\n",
    "from sklearn import metrics, model_selection\n",
    "# /Users/mli3/ml/Kaggle/train.csv\n",
    "\n",
    "def load_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# load the data\n",
    "\n",
    "train = load_data(\"data/train.csv\")\n",
    "test = load_data(\"data/test.csv\")\n",
    "\n",
    "\n",
    "train.describe()\n",
    "\n",
    "# remove columns where the value is the same for all rows (no new information)\n",
    "nunique = train.apply(pd.Series.nunique)\n",
    "col_same_train = list(nunique[nunique==1].index)\n",
    "train2 = train.drop(col_same_train,1)\n",
    "\n",
    "# apply the same to the test set\n",
    "test2 = test.drop(col_same_train, 1)\n",
    "# remove columns where the column is same as another column\n",
    "\n",
    "# hist of Y\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "y_train = train2[[\"y\"]]\n",
    "y_train.hist(bins=200, figsize=(20,15))\n",
    "plt.show()\n",
    "\n",
    "# remove row without the maximum y (looks like outliet)\n",
    "train3 = train2.loc[train2['y']!=train2['y'].max()]\n",
    "\n",
    "c = train3.corr()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind='quicksort', ascending=False)\n",
    "so['y']\n",
    "\n",
    "# remove columns that are identical and also those that are complete opposite\n",
    "col_same = s[((s==1) | (s==-1)) & (s.index.get_level_values(0) != s.index.get_level_values(1))]\n",
    "#keep the smaller of the columns\n",
    "# if x is smaller than the other columns, throw other columns out, else ignore\n",
    "dup_columns = set()\n",
    "for x,y in col_same.index:\n",
    "    if int(x[1:]) < int(y[1:]):\n",
    "        dup_columns.add(y)\n",
    "\n",
    "# there are 45+8 dup_columns\n",
    "train4 = train3.drop(list(dup_columns), 1)\n",
    "test4 = test2.drop(list(dup_columns), 1)\n",
    "# impute missing values\n",
    "\n",
    "# # this part might be unecessary\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "# imputer = Imputer(strategy=\"median\")\n",
    "\n",
    "# df_dedup_num = df_dedup.drop([\"ID\", \"y\", \"X0\",  \"X1\",  \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"], axis=1)\n",
    "# imputer.fit(df_dedup_num)\n",
    "# imputer.statistics_\n",
    "# df_dedup_num.median().values\n",
    "# X = imputer.transform(df_dedup_num)\n",
    "# df_dedup_num_tr = pd.DataFrame(X, columns=df_dedup_num.columns)\n",
    "\n",
    "# 1 hot encoding\n",
    "\n",
    "\n",
    "train_num = train4.drop([\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"], 1) # kept y column\n",
    "train_cat = train4.loc[:, [\"ID\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]]\n",
    "\n",
    "\n",
    "\n",
    "test_num = test4.drop([\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"], 1)\n",
    "test_cat = test4.loc[:, [\"ID\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]]\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "#encoder = LabelBinarizer()\n",
    "#data_dedup_cat_1hot = encoder.fit_transform(data_dedup_cat)\n",
    "#data_dedup_cat_1hot\n",
    "\n",
    "\n",
    "train_one_hot_cat = pd.get_dummies(train_cat, columns=[\"X0\", \"X1\",  \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])\n",
    "train_one_hot = train_one_hot_cat.merge(train_num, on='ID')\n",
    "\n",
    "test_one_hot_cat = pd.get_dummies(test_cat, columns=[\"X0\", \"X1\",  \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])\n",
    "test_one_hot = test_one_hot_cat.merge(test_num, on='ID')\n",
    "\n",
    "X = train_one_hot.drop(['ID', 'y'], axis=1)\n",
    "y = train_one_hot['y']\n",
    "\n",
    "\n",
    "feature_labels = X.columns\n",
    "forest = RandomForestRegressor(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "forest.fit(X, y)    # Fits the Random Forest Regressor to the entire data set.\n",
    "importances = forest.feature_importances_  # Sets importances equal to the feature importances of the model\n",
    "indices = np.argsort(importances)[::-1]\n",
    "order_features = []\n",
    "order_importances = []\n",
    "for f in range(X.shape[1]):\n",
    "    #print(\"%2d) %-*s %f\" % (f+1, 30, feature_labels[indices[f]], importances[indices[f]]))\n",
    "    order_features.append(feature_labels[f])\n",
    "    order_importances.append(importances[indices[f]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "test = test_one_hot.drop(order_features[350:], axis=1)\n",
    "train = train_one_hot.drop(order_features[350:], axis=1) # Modify train to only take in the top 100 features and the target column y\n",
    "test.info()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0_a</th>\n",
       "      <th>X0_aa</th>\n",
       "      <th>X0_ab</th>\n",
       "      <th>X0_ac</th>\n",
       "      <th>X0_ad</th>\n",
       "      <th>X0_af</th>\n",
       "      <th>X0_ai</th>\n",
       "      <th>X0_aj</th>\n",
       "      <th>X0_ak</th>\n",
       "      <th>...</th>\n",
       "      <th>X181</th>\n",
       "      <th>X182</th>\n",
       "      <th>X183</th>\n",
       "      <th>X184</th>\n",
       "      <th>X185</th>\n",
       "      <th>X186</th>\n",
       "      <th>X187</th>\n",
       "      <th>X189</th>\n",
       "      <th>X190</th>\n",
       "      <th>X191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0_a  X0_aa  X0_ab  X0_ac  X0_ad  X0_af  X0_ai  X0_aj  X0_ak  ...   \\\n",
       "0   1     0    0.0    0.0    0.0      0      0      0      0      0  ...    \n",
       "1   2     0    0.0    0.0    0.0      0      0      0      0      0  ...    \n",
       "2   3     0    0.0    0.0    0.0      0      0      0      0      0  ...    \n",
       "3   4     0    0.0    0.0    0.0      0      0      0      0      0  ...    \n",
       "4   5     0    0.0    0.0    0.0      0      0      0      0      0  ...    \n",
       "\n",
       "   X181  X182  X183  X184  X185  X186  X187  X189  X190  X191  \n",
       "0     0     0     0     0     1     0     0     0     0     0  \n",
       "1     0     0     0     0     0     1     0     1     0     0  \n",
       "2     0     0     0     0     1     0     0     0     0     1  \n",
       "3     0     0     0     0     1     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     1     1     0     1  \n",
       "\n",
       "[5 rows x 351 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_one_hot.loc[:,list(train.columns)]\n",
    "test = test.drop(['y'], axis=1)\n",
    "test = test.fillna(0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4209 entries, 0 to 4208\n",
      "Columns: 351 entries, ID to X191\n",
      "dtypes: float64(10), int64(156), uint8(185)\n",
      "memory usage: 6.1 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4208 entries, 0 to 4207\n",
      "Columns: 352 entries, ID to X191\n",
      "dtypes: float64(1), int64(156), uint8(195)\n",
      "memory usage: 5.9 MB\n"
     ]
    }
   ],
   "source": [
    "n_comp = 12\n",
    "test.info()\n",
    "train.info()\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train.drop([\"y\"], axis=1))\n",
    "tsvd_results_test = tsvd.transform(test)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train.drop([\"y\"], axis=1))\n",
    "grp_results_test = grp.transform(test)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train.drop([\"y\"], axis=1))\n",
    "srp_results_test = srp.transform(test)\n",
    "\n",
    "#save columns list before adding the decomposition components\n",
    "\n",
    "usable_columns = list(set(train.columns) - set(['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, n_comp + 1):\n",
    "    train['pca_' + str(i)] = pca2_results_train[:, i - 1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i - 1]\n",
    "\n",
    "    train['ica_' + str(i)] = ica2_results_train[:, i - 1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i - 1]\n",
    "\n",
    "    train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "\n",
    "    train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    test['srp_' + str(i)] = srp_results_test[:, i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['y'].values\n",
    "y_mean = np.mean(y_train)\n",
    "id_test = test['ID'].values\n",
    "#finaltrainset and finaltestset are data to be used only the stacked model (does not contain PCA, SVD... arrays) \n",
    "finaltrainset = train[usable_columns].values\n",
    "finaltestset = test[usable_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Train the xgb model then predict the test data'''\n",
    "\n",
    "xgb_params = {\n",
    "    'n_trees': 520, \n",
    "    'eta': 0.0045,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.93,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "num_boost_rounds = 1250\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on train data:\n",
      "0.673669917928\n",
      "Cross Validation\n",
      "................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amcfarlin/Projects/gunnars_data_championships/venv/lib/python3.4/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (3346, 411) (862, 411)\n",
      "Fitting XGBoost for Fold 1\n",
      "Fitting stacked pipeline for Fold 1\n",
      "0.567902893042\n",
      "Fold 2 (3360, 411) (848, 411)\n",
      "Fitting XGBoost for Fold 2\n",
      "Fitting stacked pipeline for Fold 2\n",
      "0.585742504179\n",
      "Fold 3 (3383, 411) (825, 411)\n",
      "Fitting XGBoost for Fold 3\n",
      "Fitting stacked pipeline for Fold 3\n",
      "0.563137995655\n",
      "Fold 4 (3390, 411) (818, 411)\n",
      "Fitting XGBoost for Fold 4\n",
      "Fitting stacked pipeline for Fold 4\n",
      "0.601438061777\n",
      "Fold 5 (3353, 411) (855, 411)\n",
      "Fitting XGBoost for Fold 5\n",
      "Fitting stacked pipeline for Fold 5\n",
      "0.612825396702\n"
     ]
    }
   ],
   "source": [
    "'''Train the stacked models then predict the test data'''\n",
    "\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ElasticNetCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=5, max_features=0.55, min_samples_leaf=18, min_samples_split=14, subsample=0.7, n_estimators=200)),\n",
    "    ElasticNetCV()\n",
    "\n",
    ")\n",
    "\n",
    "stacked_pipeline.fit(finaltrainset, y_train)\n",
    "results = stacked_pipeline.predict(finaltestset)\n",
    "\n",
    "'''R2 Score on the entire Train data when averaging'''\n",
    "\n",
    "print('R2 score on train data:')\n",
    "print(r2_score(y_train,stacked_pipeline.predict(finaltrainset)*0.2855 + model.predict(dtrain)*0.7145))\n",
    "\n",
    "\n",
    "\n",
    "'''Average the predictions test data of both models then save it on a csv file'''\n",
    "\n",
    "print('Cross Validation')\n",
    "print('................')\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\n",
    "\n",
    "X = train.drop('y', axis=1).values\n",
    "y = train['y'].values\n",
    "\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    fold += 1\n",
    "    \n",
    "    X_training, X_valid = X[train_index], X[test_index]\n",
    "    y_training, y_valid = y[train_index], y[test_index]\n",
    "    \n",
    "    finaltrainset = train[usable_columns].values\n",
    "    final_train, final_valid = finaltrainset[train_index], finaltrainset[test_index]\n",
    "    \n",
    "    print(\"Fold\", fold, X_training.shape, X_valid.shape)\n",
    "    \n",
    "    print('Fitting XGBoost for Fold {}'.format(fold))\n",
    "    dtrain = xgb.DMatrix(X_training, y_training)\n",
    "    dtest = xgb.DMatrix(X_valid)\n",
    "    model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
    "    \n",
    "    print('Fitting stacked pipeline for Fold {}'.format(fold))\n",
    "    stacked_pipeline.fit(final_train, y_training)\n",
    "    \n",
    "    print(r2_score(y_valid,stacked_pipeline.predict(final_valid)*0.2855 + model.predict(dtest)*0.7145))\n",
    "\n",
    "    \n",
    "sub = pd.DataFrame()\n",
    "sub['ID'] = id_test\n",
    "sub['y'] = y_pred*0.75 + results*0.25\n",
    "sub.to_csv('stacked-models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
